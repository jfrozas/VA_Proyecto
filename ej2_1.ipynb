{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.ndimage import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esto no funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stylization_filter(image_path):\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    smoothed_image = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    stylized_image = cv2.stylization(smoothed_image, sigma_s=60, sigma_r=0.07)\n",
    "\n",
    "    cv2.imwrite('2_1.jpg', stylized_image)\n",
    "\n",
    "stylization_filter('hoja.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El resto si\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bgr_to_grayscale(bgr_image):\n",
    "    # Extracting individual color channels\n",
    "    blue_channel = bgr_image[:,:,0]\n",
    "    green_channel = bgr_image[:,:,1]\n",
    "    red_channel = bgr_image[:,:,2]\n",
    "\n",
    "    # Applying the conversion equation\n",
    "    grayscale_image = 0.114 * blue_channel + 0.587 * green_channel + 0.299 * red_channel\n",
    "\n",
    "    # Converting to uint8 (8-bit) format\n",
    "    grayscale_image = np.uint8(grayscale_image)\n",
    "\n",
    "    return grayscale_image\n",
    "\n",
    "# Read the stylized image obtained in the previous step\n",
    "stylized_image = cv2.imread('2_1.jpg')\n",
    "\n",
    "# Convert BGR to Grayscale\n",
    "grayscale_image = bgr_to_grayscale(stylized_image)\n",
    "\n",
    "# Save the images\n",
    "cv2.imwrite('grayscale_image.jpg', grayscale_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the grayscale image\n",
    "grayscale_image = cv2.imread('grayscale_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Gaussian Blur to the grayscale image with a 9x9 kernel and sigma = 1.5\n",
    "blurred_image = cv2.GaussianBlur(grayscale_image, (9, 9), 1.5)\n",
    "\n",
    "# Save the blurred image\n",
    "cv2.imwrite('blurred_image.jpg', blurred_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the blurred image obtained in the previous step\n",
    "blurred_image = cv2.imread('blurred_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define a 3x3 integer-valued kernel for dilation\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Apply morphological dilation\n",
    "dilated_image = cv2.dilate(blurred_image, kernel, iterations=1)\n",
    "\n",
    "# Save the dilated image\n",
    "cv2.imwrite('dilated_image.jpg', dilated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dilated image obtained in the previous step\n",
    "dilated_image = cv2.imread('dilated_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define a 5x5 averaging filter kernel\n",
    "kernel_size = 5\n",
    "kernel = np.ones((kernel_size, kernel_size), np.float32) / (kernel_size * kernel_size)\n",
    "\n",
    "# Apply 2D convolution using filter2D function\n",
    "smoothed_image = cv2.filter2D(dilated_image, -1, kernel)\n",
    "\n",
    "# Save the smoothed image\n",
    "cv2.imwrite('smoothed_image.jpg', smoothed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the smoothed image obtained in the previous step\n",
    "smoothed_image = cv2.imread('smoothed_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Adaptive Thresholding\n",
    "binary_threshold_image = cv2.adaptiveThreshold(\n",
    "    smoothed_image, \n",
    "    maxValue=255, \n",
    "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "    thresholdType=cv2.THRESH_BINARY_INV,\n",
    "    blockSize=11, \n",
    "    C=1\n",
    ")\n",
    "\n",
    "# Save the binary threshold image\n",
    "cv2.imwrite('binary_threshold_image.jpg', binary_threshold_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dilated image obtained after Type Two processing\n",
    "dilated_image_type_two = cv2.imread('dilated_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Otsu's thresholding\n",
    "_, otsu_thresholded = cv2.threshold(dilated_image_type_two, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Apply Binary thresholding as a fallback\n",
    "_, binary_thresholded = cv2.threshold(dilated_image_type_two, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Combine Otsu's and Binary thresholding\n",
    "combined_thresholded = cv2.bitwise_and(otsu_thresholded, binary_thresholded)\n",
    "end = cv2.bitwise_not(combined_thresholded)\n",
    "\n",
    "# Save the combined thresholded image\n",
    "cv2.imwrite('otsu_thresholded.jpg', otsu_thresholded)\n",
    "cv2.imwrite('binary_thresholded.jpg', binary_thresholded)\n",
    "cv2.imwrite('combined_thresholded_image.jpg', combined_thresholded)\n",
    "cv2.imwrite('neg.jpg', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the combined thresholded image obtained after background separation\n",
    "combined_thresholded_image = cv2.imread('combined_thresholded_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define a kernel for morphological operations\n",
    "kernel_size = 3\n",
    "kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "\n",
    "# Perform erosion\n",
    "erosion_result = cv2.erode(combined_thresholded_image, kernel, iterations=1)\n",
    "\n",
    "# Perform dilation\n",
    "dilation_result = cv2.dilate(combined_thresholded_image, kernel, iterations=1)\n",
    "\n",
    "# Perform border extraction (subtract dilation result from erosion result)\n",
    "border_extraction = cv2.absdiff(erosion_result, dilation_result)\n",
    "\n",
    "# Save the border extraction result\n",
    "cv2.imwrite('border_extraction_result.jpg', border_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the binary threshold image\n",
    "image1 = cv2.imread(\"binary_threshold_image.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Read the border extraction result\n",
    "image2 = cv2.imread(\"border_extraction_result.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Find contours for image1\n",
    "contours1, _ = cv2.findContours(image1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Find contours for image2\n",
    "contours2, _ = cv2.findContours(image2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the contours on the original images\n",
    "contour_image1 = cv2.cvtColor(image1, cv2.COLOR_GRAY2BGR)\n",
    "cv2.drawContours(contour_image1, contours1, -1, (0, 255, 0), 2)\n",
    "\n",
    "contour_image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
    "cv2.drawContours(contour_image2, contours2, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Save the images with contours drawn\n",
    "cv2.imwrite(\"contour_image1.jpg\", contour_image1)\n",
    "cv2.imwrite(\"contour_image2.jpg\", contour_image2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
